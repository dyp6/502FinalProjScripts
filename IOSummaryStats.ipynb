{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"spark-nlp\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.5\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct, desc, year, month, dayofmonth, hour, dayofweek, to_date, to_timestamp\n",
    "import datetime\n",
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset and shoe the first few columns to confirm the format\n",
    "infoDF = spark.read.csv(\"s3://502finalprojbucky/InfOpEnglish/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------------------+----------------+\n",
      "|_c0|_c1|_c2|                 _c3|             _c4|\n",
      "+---+---+---+--------------------+----------------+\n",
      "| AL| en| en|Pain is nothing c...|2014-12-15 17:18|\n",
      "| AL| en| en|HOW CAN YOU NOT LOVE|2014-12-23 13:36|\n",
      "| AL| en| en|RT @TheMinks: Who...|2016-11-30 16:43|\n",
      "| AL| en| en|RT @f46e654ff3f1f...|2016-09-19 09:49|\n",
      "| AL| en| en|RT @lesmarie99017...|2016-12-06 07:24|\n",
      "+---+---+---+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infoDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------------------+----------------+-------------------+\n",
      "|_c0|_c1|_c2|                 _c3|             _c4|           dt_stamp|\n",
      "+---+---+---+--------------------+----------------+-------------------+\n",
      "| AL| en| en|Pain is nothing c...|2014-12-15 17:18|2014-12-15 17:18:00|\n",
      "| AL| en| en|HOW CAN YOU NOT LOVE|2014-12-23 13:36|2014-12-23 13:36:00|\n",
      "| AL| en| en|RT @TheMinks: Who...|2016-11-30 16:43|2016-11-30 16:43:00|\n",
      "| AL| en| en|RT @f46e654ff3f1f...|2016-09-19 09:49|2016-09-19 09:49:00|\n",
      "| AL| en| en|RT @lesmarie99017...|2016-12-06 07:24|2016-12-06 07:24:00|\n",
      "+---+---+---+--------------------+----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#convert the datetime stamp to a date column for future analysis\n",
    "infoDF = infoDF.withColumn('dt_stamp', to_timestamp(col('_c4'), \"yyyy-MM-dd HH:mm\").cast(\"timestamp\"))\n",
    "infoDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8536158"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns with null/na values for summary statistics \n",
    "infoDF = infoDF.filter(infoDF.dt_stamp.isNotNull())\n",
    "infoDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|count|\n",
      "+----------+-----+\n",
      "|2015-03-18|32066|\n",
      "|2017-01-30|31241|\n",
      "|2017-01-27|30028|\n",
      "|2017-01-31|27414|\n",
      "|2017-01-26|26415|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate summary statistics for date information & write to output\n",
    "dateCounts = infoDF.select(\"dt_stamp\",to_date(\"dt_stamp\",'yyyy-MM-dd').alias(\"date\"))\\\n",
    "                   .groupBy('date').count().orderBy(desc('count'))\n",
    "dateCounts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateCounts.repartition(1).write.csv(\"infoOpsDateCounts2.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|dow|  count|\n",
      "+---+-------+\n",
      "|  4|1354785|\n",
      "|  2|1286553|\n",
      "|  3|1244059|\n",
      "|  5|1238643|\n",
      "|  6|1227444|\n",
      "+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate summary statistics for day of the week\n",
    "dowCounts = infoDF.select(\"dt_stamp\",dayofweek(\"dt_stamp\").alias(\"dow\"))\\\n",
    "                   .groupBy('dow').count().orderBy(desc('count'))\n",
    "dowCounts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dowCounts.repartition(1).write.csv(\"infoOpsDOWCounts2.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
